<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Haolin Yang*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Feilong Tang*</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="">Ming Hu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Yulong Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Junjie Guo</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Zelin Peng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Junjun He</a><sup>3</sup>
            </span>
            <span class="author-block">
              <a href="">Zongyuan Ge†</a><sup>4</sup>
            </span>
            <span class="author-block">
              <a href="">Imran Razzak†</a><sup>5</sup>
<!--             </span>
            <span class="author-block">
              <a href="">Sijin Zhou</a><sup>1</sup>
            </span>
                <span class="author-block">
              <a href=""> Wenxue Li</a><sup>1</sup>
            </span>
                <span class="author-block">
              <a href="">Yulong Li</a><sup>2</sup>
            </span>
                <span class="author-block">
              <a href="">Wenxuan Song</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Shiyan Su</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Wei Feng</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Jionglong Su</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="">Minquan Lin</a><sup>6</sup>
            </span>
            <span class="author-block">
              <a href="">Yifan Peng</a><sup>7</sup>
            </span>
            <span class="author-block">
              <a href="">Xuelian Cheng</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Imran Razzak†</a><sup>8</sup>
            </span>
              <span class="author-block">
              <a href="">Zongyuan Ge†</a><sup>1</sup> -->
            </span>
            
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>MBZUAI</span>
            <span class="author-block"><sup>2</sup>Monash University</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Lab</span>
            <span class="author-block"><sup>2</sup>Nanjing Universityty</span>
            <span class="author-block"><sup>2</sup>HKUST</span>
            <span class="author-block"><sup>2</sup>Shanghai Jiaotong University</span>
<!--             <span class="author-block"><sup>2</sup>Cornell University</span>
            <span class="author-block"><sup>2</sup>University of New South Wales</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -2.6rem;">
  <figure class="image is-centered" style="width: 60%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/images/intro.png" 
      alt="image" 
      style="width: 60%; height: auto; margin-left: 25%;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
      (a): Attention Collapse in MLLMs: Outlier tokens from different modalities are assigned disproportionately high attention scores, hindering interaction between relevant tokens. (b): Positional Information Decay: As text generation progresses, attention to visual information gradually diminishes. (c): Our FarSight, as a plug-in, mitigates these issues by effectively reducing attention interference from outlier tokens and improving response accuracy.
    </figcaption>
  </figure>
</section>

  
 <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Recent advancements in multimodal large language models (MLLMs) have significantly improved performance in visual question answering. However, they often suffer from hallucinations. In this work, hallucinations are categorized into two main types: initial hallucinations and snowball hallucinations. We argue that adequate contextual information can be extracted directly from the token interaction process. Inspired by causal inference in decoding strategy, we propose to leverage causal masks to establish information propagation between multimodal tokens. The hypothesis is that insufficient interaction between those tokens may lead the model to rely on outlier tokens, overlooking dense and rich contextual cues. Therefore, we propose to intervene in the propagation process by tackling outlier tokens to enhance in-context inference. With this goal, we present FarSight, a versatile plug-and-play decoding strategy to reduce attention interference from outlier tokens merely by optimizing the causal mask. The heart of our method is effective token propagation. We design an attention register structure within the upper triangular matrix of the causal mask, dynamically allocating attention capture attention diverted to outlier tokens. Moreover, a positional awareness encoding method with a diminishing masking rate is proposed, allowing the model to attend to further preceding tokens, especially for video sequence tasks. With extensive experiments, FarSight demonstrates significant hallucination-mitigating performance across different MLLMs on both image and video benchmarks, proving its effectiveness.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Methodology</h2>
      </div>
      </div>

<!--    <section class="section" style="margin-top: -2.6rem;">
  <figure class="image is-centered" style="width: 80%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/images/method.png" 
      alt="image" 
      style="width: 100%; height: auto;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
      The scheme of the proposed FarSight strategy, which integrates with the softmax operation, replaces the traditional causal mask. Specifically, the attention score matrix ω is cleared of attention values in the upper triangular part, then register-attention scores are added using the matrix P, followed by the softmax computation. P has a linear decay in the upper triangular part and zeros in the lower triangular part. After the softmax operation, the remaining attention probabilities in the upper triangular part are cleared to ensure the causal decoding property is preserved.

    </figcaption>
  </figure>
</section> -->

  <section class="section" style="margin-top: -2.6rem;">
  <figure class="image is-centered" style="width: 80%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/images/method.png" 
      alt="image" 
      style="width: 100%; height: auto;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
      The scheme of the proposed <strong>FarSight</strong> strategy, which integrates with the <strong>softmax</strong> operation, replaces the traditional causal mask. Specifically, the attention score matrix \( \omega \) is cleared of attention values in the upper triangular part, then register-attention scores are added using the matrix \( \mathcal{P} \), followed by the softmax computation. \( \mathcal{P} \) has a linear decay in the upper triangular part and zeros in the lower triangular part. After the softmax operation, the remaining attention probabilities in the upper triangular part are cleared to ensure the causal decoding property is preserved.
    </figcaption>
  </figure>
</section>



   <div class="columns is-centered has-text-centered" style="margin-top: 0rem;">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Visualization</h2>
  </div>
</div>

<section class="section" style="margin-top: -2.6rem;">
  <figure class="image is-centered" style="width: 120%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/images/exp.png" 
      alt="image" 
      style="width: 120%; height: auto;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
     Qualitative Visualization of FarSight in Image Understanding Task on LLaVA-1.5. (a) Comparison of the average attention allocation to images during text generation among Base (Vanilla MLLMs), EDVT and our FarSight; (b) Visual attention decay across different methods within the generation of 60 text tokens; (c) FarSight's attention distribution on images under varying decay rat $\sigma$. More detailed visualizations of images and videos are provided in Appendix F.
    </figcaption>
  </figure>
</section>

<section class="section" id="BibTeX">
  <div class="container content" style="max-width: 800px; margin: 0 auto;">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      
    </code></pre>
  </div>
</section>

</body>
</html>
